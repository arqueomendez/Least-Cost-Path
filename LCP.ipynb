{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2caab9-dd63-4417-8c8d-8182fc32291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import math\n",
    "import os\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import fiona\n",
    "from fiona.crs import CRS\n",
    "from shapely.geometry import Point, LineString, mapping, shape\n",
    "from shapely.ops import unary_union\n",
    "from numba import njit\n",
    "from datetime import datetime\n",
    "from skimage.draw import disk\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.features import rasterize\n",
    "\n",
    "# --- 1. CONFIGURACIÓN DEL PROYECTO Y PARÁMETROS ---\n",
    "# Carpeta principal donde se almacenarán todas las sesiones y el log principal.\n",
    "BASE_PROCESSING_FOLDER = R\"C:\\Users\\User\\Desktop\\SofiHanna\\PROCESAMIENTO_LCP\"\n",
    "\n",
    "# --- Rutas a los datos de entrada ---\n",
    "POINTS_SUBFOLDER = os.path.join(R\"C:\\Users\\User\\Desktop\\SofiHanna\", 'puntos_por_100km')\n",
    "COST_RASTER_PATH = os.path.join(R\"C:\\Users\\User\\Desktop\\SofiHanna\", 'final_total_cost.tif')\n",
    "ALL_POINTS_SHAPEFILE = os.path.join(POINTS_SUBFOLDER, 'puntos_por_100km.shp')\n",
    "MASK_SHAPEFILE_PATH = os.path.join(R\"C:\\Users\\User\\Desktop\\SofiHanna\", 'poligono_extendido_cortado_disuelto.shp')\n",
    "\n",
    "# --- PARÁMETROS DE CÁLCULO ---\n",
    "ORIGIN_POINT_ID = 5\n",
    "ID_FIELD_NAME = 'rand_point'\n",
    "DOWNSAMPLING_FACTORS = [32, 20, 10]\n",
    "CORRIDOR_BUFFER_PIXELS = 150\n",
    "HEURISTIC_WEIGHT = 1.0\n",
    "\n",
    "# --- CLASE AUXILIAR PARA INTEGRAR LOGGING CON TQDM ---\n",
    "class TqdmLoggingHandler(logging.Handler):\n",
    "    def __init__(self, level=logging.NOTSET):\n",
    "        super().__init__(level)\n",
    "    def emit(self, record):\n",
    "        try:\n",
    "            msg = self.format(record)\n",
    "            tqdm.write(msg)\n",
    "            self.flush()\n",
    "        except (KeyboardInterrupt, SystemExit): raise\n",
    "        except Exception: self.handleError(record)\n",
    "\n",
    "# --- 2. FUNCIONES AUXILIARES ---\n",
    "def load_all_points(shapefile_path, id_field):\n",
    "    points = {}; crs = None\n",
    "    try:\n",
    "        with fiona.open(shapefile_path, 'r') as c:\n",
    "            crs = c.crs\n",
    "            if len(c) == 0: logging.error(f\"'{os.path.basename(shapefile_path)}' está vacío.\"); return None, None\n",
    "            for f in c: points[int(f['properties'][id_field])] = f['geometry']['coordinates']\n",
    "        return points, crs\n",
    "    except Exception as e: logging.error(f\"Error cargando puntos: {e}\"); return None, None\n",
    "\n",
    "def load_polygon_geometry(shapefile_path):\n",
    "    if not shapefile_path or not os.path.exists(shapefile_path): return None\n",
    "    try:\n",
    "        with fiona.open(shapefile_path, 'r') as c:\n",
    "            if len(c) == 0: logging.warning(f\"'{os.path.basename(shapefile_path)}' de máscara está vacío.\"); return None\n",
    "            return unary_union([shape(f['geometry']) for f in c])\n",
    "    except Exception as e: logging.error(f\"Error cargando polígono: {e}\"); return None\n",
    "\n",
    "def world_to_pixel(transform, x, y):\n",
    "    col, row = ~transform * (x, y); return int(row), int(col)\n",
    "\n",
    "def create_mask_from_vector(vector_path, raster_src):\n",
    "    if not vector_path or not os.path.exists(vector_path):\n",
    "        logging.warning(\"No se encontró archivo de máscara.\"); return None\n",
    "    with fiona.open(vector_path, \"r\") as vf:\n",
    "        if vf.crs != raster_src.crs:\n",
    "            logging.critical(f\"CRS de máscara ({vf.crs}) y ráster ({raster_src.crs}) no coinciden.\"); return None\n",
    "        shapes = [f[\"geometry\"] for f in vf]\n",
    "    return rasterize(shapes, out_shape=raster_src.shape, transform=raster_src.transform, fill=0, all_touched=True, dtype=np.uint8).astype(bool)\n",
    "\n",
    "# --- 3. ALGORITMO A* Y HELPERS ---\n",
    "@njit\n",
    "def heuristic_numba(r1, c1, r2, c2, dx, dy): return math.sqrt((r2 - r1)**2 + (c2 - c1)**2) * math.sqrt(dx*dy)\n",
    "@njit\n",
    "def a_star_numba_compiled(cost_array, nodata_value, start_pixel, end_pixel, dx, dy, weight, search_mask):\n",
    "    height, width = cost_array.shape; g_cost = np.full(cost_array.shape, np.inf); came_from = np.full(cost_array.shape, -1, dtype=np.int16)\n",
    "    open_set = np.zeros((1, 4)); h_initial = heuristic_numba(start_pixel[0], start_pixel[1], end_pixel[0], end_pixel[1], dx, dy)\n",
    "    open_set[0] = [h_initial*weight, 0.0, start_pixel[0], start_pixel[1]]; g_cost[start_pixel] = 0; path_found = False\n",
    "    while open_set.shape[0] > 0:\n",
    "        min_idx = np.argmin(open_set[:, 0]); f, g, r, c = open_set[min_idx]; current_pos = (int(r), int(c))\n",
    "        if open_set.shape[0] == 1: open_set = np.zeros((0, 4))\n",
    "        else: open_set = np.vstack((open_set[:min_idx], open_set[min_idx + 1:]))\n",
    "        if current_pos == end_pixel: path_found = True; break\n",
    "        if g > g_cost[current_pos]: continue\n",
    "        cost_current = cost_array[current_pos]\n",
    "        for dr in range(-1, 2):\n",
    "            for dc in range(-1, 2):\n",
    "                if dr == 0 and dc == 0: continue\n",
    "                neighbor_pos = (current_pos[0] + dr, current_pos[1] + dc)\n",
    "                if not (0 <= neighbor_pos[0] < height and 0 <= neighbor_pos[1] < width): continue\n",
    "                if not search_mask[neighbor_pos]: continue\n",
    "                cost_neighbor = cost_array[neighbor_pos];\n",
    "                if cost_neighbor == nodata_value: continue\n",
    "                dist_m = math.sqrt((dr*dy)**2 + (dc*dx)**2); avg_cost = (cost_current + cost_neighbor) / 2.0\n",
    "                tentative_g_cost = g + (avg_cost*dist_m)\n",
    "                if tentative_g_cost < g_cost[neighbor_pos]:\n",
    "                    direction = (dr+1)*3 + (dc+1); came_from[neighbor_pos] = direction; g_cost[neighbor_pos] = tentative_g_cost\n",
    "                    h = heuristic_numba(neighbor_pos[0], neighbor_pos[1], end_pixel[0], end_pixel[1], dx, dy)\n",
    "                    new_f_cost = tentative_g_cost + (h*weight)\n",
    "                    new_entry = np.array([[new_f_cost, tentative_g_cost, neighbor_pos[0], neighbor_pos[1]]])\n",
    "                    open_set = np.vstack((open_set, new_entry))\n",
    "    return path_found, came_from, g_cost\n",
    "@njit\n",
    "def reconstruct_path_pixels_numba(came_from_array, start_pixel, end_pixel):\n",
    "    path = np.zeros((came_from_array.size, 2), dtype=np.int32); current_pos_r, current_pos_c = end_pixel; count = 0; limit = came_from_array.size\n",
    "    while (current_pos_r, current_pos_c) != start_pixel and count < limit:\n",
    "        path[count] = np.array([current_pos_r, current_pos_c]); direction = came_from_array[current_pos_r, current_pos_c]\n",
    "        if direction == -1: return None\n",
    "        dc = (direction % 3) - 1; dr = (direction // 3) - 1; current_pos_r -= dr; current_pos_c -= dc; count += 1\n",
    "    path[count] = np.array([start_pixel[0], start_pixel[1]]); return path[:count+1][::-1]\n",
    "\n",
    "# --- 4. FUNCIONES PARA BÚSQUEDA JERÁRQUICA ---\n",
    "def create_low_res_data(src, factor):\n",
    "    low_res_shape = (src.height // factor, src.width // factor)\n",
    "    low_res_data = src.read(1, out_shape=low_res_shape, resampling=Resampling.average)\n",
    "    low_res_transform = src.transform * src.transform.scale(factor, factor)\n",
    "    return low_res_data, low_res_transform, src.res[0]*factor, src.res[1]*factor\n",
    "def create_search_corridor(path_low_res, high_res_shape, factor, buffer_pixels):\n",
    "    corridor_mask = np.zeros(high_res_shape, dtype=bool);\n",
    "    if path_low_res is None: return corridor_mask\n",
    "    for r_low, c_low in path_low_res:\n",
    "        r_high = int(r_low*factor + factor/2); c_high = int(c_low*factor + factor/2)\n",
    "        rr, cc = disk((r_high, c_high), buffer_pixels, shape=high_res_shape); corridor_mask[rr, cc] = True\n",
    "    return corridor_mask\n",
    "def save_path_to_shapefile(pixel_path, transform, crs, output_path):\n",
    "    if pixel_path is None or not pixel_path.any():\n",
    "        logging.warning(f\"No se guardará {os.path.basename(output_path)}, ruta vacía.\"); return\n",
    "    world_coords = [transform * (p[1] + 0.5, p[0] + 0.5) for p in pixel_path]\n",
    "    schema = {'geometry': 'LineString', 'properties': {'id': 'str'}}\n",
    "    with fiona.open(output_path, 'w', 'ESRI Shapefile', schema, crs=CRS.from_wkt(crs.to_wkt()) if crs else None) as c:\n",
    "        c.write({'geometry': mapping(LineString(world_coords)), 'properties': {'id': os.path.basename(output_path)}})\n",
    "\n",
    "# --- 5. EJECUCIÓN DEL ANÁLISIS ---\n",
    "if __name__ == '__main__':\n",
    "    os.makedirs(BASE_PROCESSING_FOLDER, exist_ok=True)\n",
    "    \n",
    "    # --- Configurar el logger maestro persistente ---\n",
    "    log_file_path = os.path.join(BASE_PROCESSING_FOLDER, \"registro_maestro_procesamiento.log\")\n",
    "    log = logging.getLogger(); log.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    if not log.handlers:\n",
    "        file_handler = logging.FileHandler(log_file_path, mode='a'); file_handler.setFormatter(formatter); log.addHandler(file_handler)\n",
    "        tqdm_handler = TqdmLoggingHandler(); tqdm_handler.setFormatter(formatter); log.addHandler(tqdm_handler)\n",
    "\n",
    "    log.info(\"=========================================================\")\n",
    "    log.info(\"============== INICIANDO NUEVA EJECUCIÓN ==============\")\n",
    "    log.info(\"=========================================================\")\n",
    "\n",
    "    try:\n",
    "        all_points, points_crs = load_all_points(ALL_POINTS_SHAPEFILE, ID_FIELD_NAME)\n",
    "        if not all_points:\n",
    "             raise ValueError(\"No se pudieron cargar los puntos de entrada. Verifique el log de errores.\")\n",
    "\n",
    "        # --- LÓGICA DE REANUDACIÓN AUTOMÁTICA ---\n",
    "        num_expected_routes = len(all_points) - 1\n",
    "        session_to_resume = None\n",
    "        \n",
    "        try:\n",
    "            existing_sessions = [d for d in os.listdir(BASE_PROCESSING_FOLDER) if os.path.isdir(os.path.join(BASE_PROCESSING_FOLDER, d)) and d[:8].isdigit()]\n",
    "        except FileNotFoundError:\n",
    "            existing_sessions = []\n",
    "\n",
    "        if existing_sessions:\n",
    "            existing_sessions.sort()\n",
    "            latest_session_name = existing_sessions[-1]\n",
    "            latest_session_path = os.path.join(BASE_PROCESSING_FOLDER, latest_session_name)\n",
    "            \n",
    "            completed_routes = [f for f in os.listdir(latest_session_path) if f.startswith(f\"ruta_final_desde_{ORIGIN_POINT_ID}_a_\") and f.endswith(\".shp\")]\n",
    "            \n",
    "            if len(completed_routes) < num_expected_routes:\n",
    "                session_to_resume = latest_session_name\n",
    "\n",
    "        if session_to_resume:\n",
    "            SESSION_OUTPUT_DIR = os.path.join(BASE_PROCESSING_FOLDER, session_to_resume)\n",
    "            log.info(f\"MODO REANUDACIÓN AUTOMÁTICA: La última sesión '{session_to_resume}' está incompleta. Reanudando...\")\n",
    "        else:\n",
    "            if existing_sessions:\n",
    "                log.info(f\"La última sesión '{existing_sessions[-1]}' se encontró completa.\")\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            session_folder_name = f\"{timestamp}_desde_punto_{ORIGIN_POINT_ID}\"\n",
    "            SESSION_OUTPUT_DIR = os.path.join(BASE_PROCESSING_FOLDER, session_folder_name)\n",
    "            log.info(f\"MODO NUEVO: Creando nueva carpeta de sesión: {session_folder_name}\")\n",
    "        os.makedirs(SESSION_OUTPUT_DIR, exist_ok=True)\n",
    "        # --- FIN DE LA LÓGICA DE REANUDACIÓN ---\n",
    "\n",
    "        with rasterio.open(COST_RASTER_PATH) as src:\n",
    "            log.info(\"Cargando superficie de coste de alta resolución en RAM...\")\n",
    "            cost_data_high_res = src.read(1)\n",
    "            mask_polygon_geom = load_polygon_geometry(MASK_SHAPEFILE_PATH)\n",
    "            if mask_polygon_geom:\n",
    "                log.info(\"Creando máscara de búsqueda rasterizada...\")\n",
    "                search_mask_hr_user = create_mask_from_vector(MASK_SHAPEFILE_PATH, src)\n",
    "                log.info(\"\\n--- VERIFICACIÓN PRELIMINAR DE PUNTOS CONTRA LA MÁSCARA ---\")\n",
    "                invalid_points_ids = [str(pid) for pid, coords in all_points.items() if not mask_polygon_geom.contains(Point(coords))]\n",
    "                if invalid_points_ids:\n",
    "                    log.critical(\"¡ANÁLISIS CANCELADO! Puntos fuera de la máscara: \" + \", \".join(invalid_points_ids)); exit()\n",
    "                else: log.info(\"VERIFICACIÓN SUPERADA: Todos los puntos están dentro del área.\")\n",
    "\n",
    "            origin_coords = all_points.get(ORIGIN_POINT_ID)\n",
    "            start_pixel_hr = world_to_pixel(src.transform, origin_coords[0], origin_coords[1])\n",
    "            log.info(f\"\\nInicio del cálculo. Origen Fijo: Punto ID {ORIGIN_POINT_ID} -> Píxel {start_pixel_hr}\")\n",
    "            \n",
    "            for dest_id, dest_coords in tqdm(all_points.items(), desc=\"Calculando rutas\"):\n",
    "                if dest_id == ORIGIN_POINT_ID: continue\n",
    "                \n",
    "                final_output_path = os.path.join(SESSION_OUTPUT_DIR, f\"ruta_final_desde_{ORIGIN_POINT_ID}_a_{dest_id}.shp\")\n",
    "                if os.path.exists(final_output_path):\n",
    "                    log.info(f\"Ruta para {ORIGIN_POINT_ID}->{dest_id} ya existe. Omitiendo.\"); continue\n",
    "                \n",
    "                log.info(f\"\\n--- Calculando ruta desde {ORIGIN_POINT_ID} hasta {dest_id} ---\")\n",
    "                end_pixel_hr = world_to_pixel(src.transform, dest_coords[0], dest_coords[1])\n",
    "                \n",
    "                path_found_lr, path_pixels_lr, successful_factor, trans_low = False, None, None, None\n",
    "                log.info(\"-> FASE 1: Búsqueda en baja resolución...\")\n",
    "                for factor in DOWNSAMPLING_FACTORS:\n",
    "                    log.info(f\"Probando con factor: {factor}...\")\n",
    "                    cost_data_lr, trans_lr, dx_lr, dy_lr = create_low_res_data(src, factor)\n",
    "                    search_mask_lr = search_mask_hr_user[::factor, ::factor] if search_mask_hr_user is not None else np.ones(cost_data_lr.shape, dtype=bool)\n",
    "                    start_lr = (start_pixel_hr[0]//factor, start_pixel_hr[1]//factor); end_lr = (end_pixel_hr[0]//factor, end_pixel_hr[1]//factor)\n",
    "                    found, came_from_lr, _ = a_star_numba_compiled(cost_data_lr, src.nodata, start_lr, end_lr, dx_lr, abs(dy_lr), HEURISTIC_WEIGHT, search_mask_lr)\n",
    "                    if found:\n",
    "                        log.info(f\"ÉXITO con factor {factor}.\"); path_found_lr, successful_factor, trans_low = True, factor, trans_lr\n",
    "                        path_pixels_lr = reconstruct_path_pixels_numba(came_from_lr, start_lr, end_lr); break\n",
    "                    else: log.info(f\"FALLÓ con factor {factor}.\")\n",
    "                \n",
    "                if not path_found_lr: log.warning(f\"Fase 1 fallida para {ORIGIN_POINT_ID}->{dest_id}.\")\n",
    "\n",
    "                log.info(\"-> FASE 2: Búsqueda en alta resolución...\")\n",
    "                path_found_hr, came_from_hr = False, None\n",
    "                if path_found_lr:\n",
    "                    log.info(\"Creando corredor y buscando dentro...\")\n",
    "                    corridor_mask = create_search_corridor(path_pixels_lr, cost_data_high_res.shape, successful_factor, CORRIDOR_BUFFER_PIXELS)\n",
    "                    final_mask = np.logical_and(corridor_mask, search_mask_hr_user) if search_mask_hr_user is not None else corridor_mask\n",
    "                    path_found_hr, came_from_hr, _ = a_star_numba_compiled(cost_data_high_res, src.nodata, start_pixel_hr, end_pixel_hr, src.res[0], abs(src.res[1]), HEURISTIC_WEIGHT, final_mask)\n",
    "                \n",
    "                if not path_found_hr:\n",
    "                    if path_found_lr: log.warning(\"Búsqueda en corredor falló.\")\n",
    "                    log.info(\"PLAN B: Realizando LCP sobre toda la máscara...\")\n",
    "                    fallback_mask = search_mask_hr_user if search_mask_hr_user is not None else np.ones_like(cost_data_high_res, dtype=bool)\n",
    "                    path_found_hr, came_from_hr, _ = a_star_numba_compiled(cost_data_high_res, src.nodata, start_pixel_hr, end_pixel_hr, src.res[0], abs(src.res[1]), HEURISTIC_WEIGHT, fallback_mask)\n",
    "                \n",
    "                if path_found_hr:\n",
    "                    log.info(f\"-> ÉXITO: Ruta final encontrada para {ORIGIN_POINT_ID}->{dest_id}.\")\n",
    "                    path_pixels_hr = reconstruct_path_pixels_numba(came_from_hr, start_pixel_hr, end_pixel_hr)\n",
    "                    if path_found_lr:\n",
    "                        p1_path = os.path.join(SESSION_OUTPUT_DIR, f\"ruta_fase1_desde_{ORIGIN_POINT_ID}_a_{dest_id}.shp\")\n",
    "                        save_path_to_shapefile(path_pixels_lr, trans_low, src.crs, p1_path)\n",
    "                    save_path_to_shapefile(path_pixels_hr, src.transform, src.crs, final_output_path)\n",
    "                else:\n",
    "                    log.error(f\"-> ERROR CRÍTICO: No se encontró ruta de alto nivel para {ORIGIN_POINT_ID}->{dest_id}.\")\n",
    "            \n",
    "            log.info(\"\\n¡Proceso de Uno a Todos completado!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.critical(f\"Ocurrió un error inesperado en el proceso principal: {e}\", exc_info=True)\n",
    "    \n",
    "    log.info(\"================== EJECUCIÓN FINALIZADA ==================\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
