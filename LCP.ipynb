{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2caab9-dd63-4417-8c8d-8182fc32291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import math\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import fiona\n",
    "from fiona.crs import CRS\n",
    "from shapely.geometry import Point, LineString, mapping, shape\n",
    "from shapely.ops import unary_union\n",
    "from numba import njit\n",
    "from datetime import datetime\n",
    "from skimage.draw import disk\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.features import rasterize\n",
    "\n",
    "# --- 1. CONFIGURACIÓN DEL PROYECTO Y PARÁMETROS ---\n",
    "BASE_PATH = R\"C:\\Users\\User\\Desktop\\SofiHanna\"\n",
    "POINTS_SUBFOLDER = os.path.join(BASE_PATH, 'puntos_por_100km')\n",
    "COST_RASTER_PATH = os.path.join(BASE_PATH, 'final_total_cost.tif')\n",
    "\n",
    "# --- PARÁMETROS DE ENTRADA Y SALIDA ---\n",
    "ALL_POINTS_SHAPEFILE = os.path.join(POINTS_SUBFOLDER, 'puntos_por_100km.shp')\n",
    "ORIGIN_POINT_ID = 5\n",
    "ID_FIELD_NAME = 'rand_point'\n",
    "\n",
    "# --- PARÁMETRO PARA LA MÁSCARA DE BÚSQUEDA ---\n",
    "MASK_SHAPEFILE_PATH = os.path.join(BASE_PATH, 'poligono_extendido_cortado_disuelto.shp')\n",
    "\n",
    "# --- PARÁMETROS DE LA BÚSQUEDA JERÁRQUICA ---\n",
    "DOWNSAMPLING_FACTORS = [32, 20, 10]\n",
    "CORRIDOR_BUFFER_PIXELS = 150\n",
    "HEURISTIC_WEIGHT = 1.0\n",
    "\n",
    "# --- 2. FUNCIONES AUXILIARES ---\n",
    "\n",
    "def load_all_points(shapefile_path, id_field):\n",
    "    \"\"\"Carga todos los puntos y sus IDs desde un shapefile a un diccionario.\"\"\"\n",
    "    points = {}\n",
    "    crs = None\n",
    "    try:\n",
    "        with fiona.open(shapefile_path, 'r') as collection:\n",
    "            crs = collection.crs\n",
    "            if len(collection) == 0:\n",
    "                print(f\"Error: El shapefile '{os.path.basename(shapefile_path)}' está vacío.\")\n",
    "                return None, None\n",
    "            for feature in collection:\n",
    "                point_id = int(feature['properties'][id_field])\n",
    "                coords = feature['geometry']['coordinates']\n",
    "                points[point_id] = coords\n",
    "        return points, crs\n",
    "    except Exception as e:\n",
    "        print(f\"Error cargando los puntos desde {shapefile_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def load_polygon_geometry(shapefile_path):\n",
    "    \"\"\"Carga y disuelve la geometría de un shapefile de polígonos.\"\"\"\n",
    "    if not shapefile_path or not os.path.exists(shapefile_path):\n",
    "        return None\n",
    "    try:\n",
    "        with fiona.open(shapefile_path, 'r') as collection:\n",
    "            if len(collection) == 0:\n",
    "                print(f\"Advertencia: El shapefile de máscara '{os.path.basename(shapefile_path)}' está vacío.\")\n",
    "                return None\n",
    "            geometries = [shape(feature['geometry']) for feature in collection]\n",
    "            return unary_union(geometries)\n",
    "    except Exception as e:\n",
    "        print(f\"Error cargando la geometría del polígono desde {shapefile_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def world_to_pixel(transform, x, y):\n",
    "    col, row = ~transform * (x, y); return int(row), int(col)\n",
    "\n",
    "def create_mask_from_vector(vector_path, raster_src):\n",
    "    \"\"\"Rasteriza un archivo vectorial para crear una máscara booleana.\"\"\"\n",
    "    if not vector_path or not os.path.exists(vector_path):\n",
    "        print(\"Advertencia: No se proporcionó o no se encontró el archivo de máscara. No se aplicará la máscara.\")\n",
    "        return None\n",
    "\n",
    "    with fiona.open(vector_path, \"r\") as vector_file:\n",
    "        if vector_file.crs != raster_src.crs:\n",
    "            print(f\"¡ERROR CRÍTICO DE CRS! El CRS de la máscara ({vector_file.crs}) no coincide con el del ráster ({raster_src.crs}).\")\n",
    "            return None\n",
    "        \n",
    "        shapes = [feature[\"geometry\"] for feature in vector_file]\n",
    "\n",
    "    mask = rasterize(\n",
    "        shapes,\n",
    "        out_shape=raster_src.shape,\n",
    "        transform=raster_src.transform,\n",
    "        fill=0,\n",
    "        all_touched=True,\n",
    "        dtype=np.uint8\n",
    "    )\n",
    "    \n",
    "    return mask.astype(bool)\n",
    "\n",
    "# --- 3. ALGORITMO A* Y HELPERS (COMPILADOS CON NUMBA) ---\n",
    "\n",
    "@njit\n",
    "def heuristic_numba(r1, c1, r2, c2, dx, dy):\n",
    "    return math.sqrt((r2 - r1)**2 + (c2 - c1)**2) * math.sqrt(dx * dy)\n",
    "\n",
    "@njit\n",
    "def a_star_numba_compiled(cost_array, nodata_value, start_pixel, end_pixel, dx, dy, weight, search_mask):\n",
    "    height, width = cost_array.shape\n",
    "    g_cost = np.full(cost_array.shape, np.inf, dtype=np.float64)\n",
    "    came_from = np.full(cost_array.shape, -1, dtype=np.int16)\n",
    "    open_set = np.zeros((1, 4), dtype=np.float64)\n",
    "    h_initial = heuristic_numba(start_pixel[0], start_pixel[1], end_pixel[0], end_pixel[1], dx, dy)\n",
    "    open_set[0] = [h_initial * weight, 0.0, start_pixel[0], start_pixel[1]]\n",
    "    g_cost[start_pixel] = 0\n",
    "    path_found = False\n",
    "    \n",
    "    while open_set.shape[0] > 0:\n",
    "        min_idx = np.argmin(open_set[:, 0])\n",
    "        f, g, r, c = open_set[min_idx]; current_pos = (int(r), int(c))\n",
    "        if open_set.shape[0] == 1: open_set = np.zeros((0, 4), dtype=np.float64)\n",
    "        else: open_set = np.vstack((open_set[:min_idx], open_set[min_idx + 1:]))\n",
    "        \n",
    "        if current_pos == end_pixel: path_found = True; break\n",
    "        if g > g_cost[current_pos]: continue\n",
    "            \n",
    "        cost_current = cost_array[current_pos]\n",
    "        \n",
    "        for dr in range(-1, 2):\n",
    "            for dc in range(-1, 2):\n",
    "                if dr == 0 and dc == 0: continue\n",
    "                neighbor_pos = (current_pos[0] + dr, current_pos[1] + dc)\n",
    "                if not (0 <= neighbor_pos[0] < height and 0 <= neighbor_pos[1] < width): continue\n",
    "                if not search_mask[neighbor_pos]: continue\n",
    "                cost_neighbor = cost_array[neighbor_pos]\n",
    "                if cost_neighbor == nodata_value: continue\n",
    "                dist_m = math.sqrt((dr * dy)**2 + (dc * dx)**2)\n",
    "                avg_cost = (cost_current + cost_neighbor) / 2.0\n",
    "                tentative_g_cost = g + (avg_cost * dist_m)\n",
    "                \n",
    "                if tentative_g_cost < g_cost[neighbor_pos]:\n",
    "                    direction = (dr+1)*3 + (dc+1)\n",
    "                    came_from[neighbor_pos] = direction; g_cost[neighbor_pos] = tentative_g_cost\n",
    "                    h = heuristic_numba(neighbor_pos[0], neighbor_pos[1], end_pixel[0], end_pixel[1], dx, dy)\n",
    "                    new_f_cost = tentative_g_cost + (h * weight)\n",
    "                    new_entry = np.array([[new_f_cost, tentative_g_cost, neighbor_pos[0], neighbor_pos[1]]], dtype=np.float64)\n",
    "                    if open_set.shape[0] == 0: open_set = new_entry\n",
    "                    else: open_set = np.vstack((open_set, new_entry))\n",
    "    \n",
    "    return path_found, came_from, g_cost\n",
    "\n",
    "@njit\n",
    "def reconstruct_path_pixels_numba(came_from_array, start_pixel, end_pixel):\n",
    "    path = np.zeros((came_from_array.size, 2), dtype=np.int32)\n",
    "    current_pos_r, current_pos_c = end_pixel\n",
    "    count = 0\n",
    "    limit = came_from_array.size\n",
    "    \n",
    "    while (current_pos_r, current_pos_c) != start_pixel and count < limit:\n",
    "        path[count] = np.array([current_pos_r, current_pos_c], dtype=np.int32)\n",
    "        direction = came_from_array[current_pos_r, current_pos_c]\n",
    "        if direction == -1: return None\n",
    "        dc = (direction % 3) - 1; dr = (direction // 3) - 1\n",
    "        current_pos_r -= dr; current_pos_c -= dc\n",
    "        count += 1\n",
    "        \n",
    "    path[count] = np.array([start_pixel[0], start_pixel[1]], dtype=np.int32)\n",
    "    return path[:count+1][::-1]\n",
    "\n",
    "# --- 4. FUNCIONES PARA BÚSQUEDA JERÁRQUICA ---\n",
    "\n",
    "def create_low_res_data(src, factor):\n",
    "    low_res_shape = (src.height // factor, src.width // factor)\n",
    "    low_res_data = src.read(1, out_shape=low_res_shape, resampling=Resampling.average)\n",
    "    low_res_transform = src.transform * src.transform.scale(factor, factor)\n",
    "    low_res_dx = src.res[0] * factor\n",
    "    low_res_dy = src.res[1] * factor\n",
    "    return low_res_data, low_res_transform, low_res_dx, low_res_dy\n",
    "\n",
    "def create_search_corridor(path_low_res, high_res_shape, factor, buffer_pixels):\n",
    "    corridor_mask = np.zeros(high_res_shape, dtype=bool)\n",
    "    if path_low_res is None: return corridor_mask\n",
    "    for r_low, c_low in path_low_res:\n",
    "        r_high = int(r_low * factor + factor / 2)\n",
    "        c_high = int(c_low * factor + factor / 2)\n",
    "        rr, cc = disk((r_high, c_high), buffer_pixels, shape=high_res_shape)\n",
    "        corridor_mask[rr, cc] = True\n",
    "    return corridor_mask\n",
    "\n",
    "def save_path_to_shapefile(pixel_path, transform, crs, output_path):\n",
    "    if not pixel_path.any():\n",
    "        tqdm.write(f\"  ADVERTENCIA: No se guardará el archivo {output_path} porque la ruta está vacía.\")\n",
    "        return\n",
    "    world_coords = [transform * (p[1] + 0.5, p[0] + 0.5) for p in pixel_path]\n",
    "    schema = {'geometry': 'LineString', 'properties': {'id': 'str'}}\n",
    "    with fiona.open(output_path, 'w', 'ESRI Shapefile', schema, crs=CRS.from_wkt(crs.to_wkt()) if crs else None) as c:\n",
    "        c.write({'geometry': mapping(LineString(world_coords)), 'properties': {'id': os.path.basename(output_path)}})\n",
    "\n",
    "# --- 5. EJECUCIÓN DEL ANÁLISIS DE UNO A TODOS ---\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        OUTPUT_DIR = os.path.join(BASE_PATH, f\"rutas_desde_punto_{ORIGIN_POINT_ID}_{timestamp}\")\n",
    "        os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "        print(f\"Los resultados se guardarán en: {OUTPUT_DIR}\")\n",
    "        \n",
    "        all_points, points_crs = load_all_points(ALL_POINTS_SHAPEFILE, ID_FIELD_NAME)\n",
    "\n",
    "        if all_points:\n",
    "            with rasterio.open(COST_RASTER_PATH) as src:\n",
    "                if not (src.crs == points_crs):\n",
    "                    print(\"¡ERROR CRÍTICO: El CRS de los puntos y el del ráster no coinciden!\")\n",
    "                else:\n",
    "                    print(\"Cargando superficie de coste de alta resolución en RAM...\")\n",
    "                    cost_data_high_res = src.read(1)\n",
    "                    \n",
    "                    mask_polygon_geom = None\n",
    "                    search_mask_hr_user = None\n",
    "                    if MASK_SHAPEFILE_PATH:\n",
    "                        print(f\"\\nCargando geometría de la máscara desde: {os.path.basename(MASK_SHAPEFILE_PATH)}...\")\n",
    "                        mask_polygon_geom = load_polygon_geometry(MASK_SHAPEFILE_PATH)\n",
    "                        if mask_polygon_geom:\n",
    "                            print(f\"Creando máscara de búsqueda rasterizada...\")\n",
    "                            search_mask_hr_user = create_mask_from_vector(MASK_SHAPEFILE_PATH, src)\n",
    "\n",
    "                    if mask_polygon_geom and all_points:\n",
    "                        print(\"\\n--- VERIFICACIÓN PRELIMINAR DE PUNTOS CONTRA LA MÁSCARA ---\")\n",
    "                        invalid_points_ids = []\n",
    "                        for point_id, coords in all_points.items():\n",
    "                            point_geom = Point(coords)\n",
    "                            is_inside = mask_polygon_geom.contains(point_geom)\n",
    "                            status = \"DENTRO\" if is_inside else \"FUERA\"\n",
    "                            print(f\"  Punto ID {point_id}: está {status} del polígono de máscara.\")\n",
    "                            if not is_inside:\n",
    "                                invalid_points_ids.append(str(point_id))\n",
    "\n",
    "                        print(\"---------------------------------------------------------\")\n",
    "\n",
    "                        if invalid_points_ids:\n",
    "                            print(\"\\n¡ERROR CRÍTICO! El análisis se ha cancelado porque los siguientes puntos están FUERA del polígono de la máscara:\")\n",
    "                            print(f\"  -> IDs de puntos no válidos: {', '.join(invalid_points_ids)}\")\n",
    "                            print(\"  Por favor, corrija las coordenadas de estos puntos o ajuste el polígono de la máscara antes de volver a ejecutar.\")\n",
    "                            exit()\n",
    "                        else:\n",
    "                            print(\"VERIFICACIÓN SUPERADA: Todos los puntos están dentro del área de la máscara.\")\n",
    "                    \n",
    "                    origin_coords = all_points.get(ORIGIN_POINT_ID)\n",
    "                    if not origin_coords:\n",
    "                        print(f\"Error: No se encontró el punto de origen con ID={ORIGIN_POINT_ID} en el shapefile.\")\n",
    "                        exit()\n",
    "                    \n",
    "                    start_pixel_hr = world_to_pixel(src.transform, origin_coords[0], origin_coords[1])\n",
    "                    print(f\"\\nInicio del cálculo. Origen Fijo: Punto ID {ORIGIN_POINT_ID} -> Píxel {start_pixel_hr}\")\n",
    "                    \n",
    "                    for dest_id, dest_coords in tqdm(all_points.items(), desc=\"Calculando rutas\"):\n",
    "                        if dest_id == ORIGIN_POINT_ID:\n",
    "                            continue\n",
    "                        \n",
    "                        tqdm.write(f\"\\n--- Calculando ruta desde {ORIGIN_POINT_ID} hasta {dest_id} ---\")\n",
    "                        \n",
    "                        end_pixel_hr = world_to_pixel(src.transform, dest_coords[0], dest_coords[1])\n",
    "                        \n",
    "                        path_found_lr = False\n",
    "                        path_pixels_lr = None\n",
    "                        successful_factor = None\n",
    "                        trans_low = None\n",
    "                        \n",
    "                        tqdm.write(\"  -> FASE 1: Búsqueda en baja resolución...\")\n",
    "                        for factor in DOWNSAMPLING_FACTORS:\n",
    "                            tqdm.write(f\"     Probando con downsampling factor: {factor}...\")\n",
    "                            cost_data_low_res_iter, trans_low_iter, dx_low, dy_low = create_low_res_data(src, factor)\n",
    "                            \n",
    "                            search_mask_low_res_user = search_mask_hr_user[::factor, ::factor] if search_mask_hr_user is not None else np.ones(cost_data_low_res_iter.shape, dtype=bool)\n",
    "\n",
    "                            start_pixel_lr = (start_pixel_hr[0] // factor, start_pixel_hr[1] // factor)\n",
    "                            end_pixel_lr = (end_pixel_hr[0] // factor, end_pixel_hr[1] // factor)\n",
    "                            \n",
    "                            current_path_found, came_from_lr, _ = a_star_numba_compiled(\n",
    "                                cost_data_low_res_iter, src.nodata, start_pixel_lr, end_pixel_lr, dx_low, abs(dy_low), HEURISTIC_WEIGHT, search_mask_low_res_user\n",
    "                            )\n",
    "                            \n",
    "                            if current_path_found:\n",
    "                                tqdm.write(f\"     ÉXITO: Ruta encontrada con factor {factor}.\")\n",
    "                                path_found_lr = True\n",
    "                                path_pixels_lr = reconstruct_path_pixels_numba(came_from_lr, start_pixel_lr, end_pixel_lr)\n",
    "                                successful_factor = factor\n",
    "                                trans_low = trans_low_iter\n",
    "                                break\n",
    "                            else:\n",
    "                                tqdm.write(f\"     FALLÓ con factor {factor}.\")\n",
    "                        \n",
    "                        if not path_found_lr:\n",
    "                            tqdm.write(f\"  -> ADVERTENCIA: Fase 1 fallida. No se encontró ruta de bajo nivel para {ORIGIN_POINT_ID}->{dest_id} con ninguno de los factores {DOWNSAMPLING_FACTORS}.\")\n",
    "\n",
    "                        tqdm.write(\"  -> FASE 2: Búsqueda en alta resolución...\")\n",
    "                        path_found_hr = False\n",
    "                        came_from_hr = None\n",
    "\n",
    "                        if path_found_lr:\n",
    "                            tqdm.write(\"     Creando corredor y buscando dentro de él...\")\n",
    "                            search_mask_hr_corridor = create_search_corridor(path_pixels_lr, cost_data_high_res.shape, successful_factor, CORRIDOR_BUFFER_PIXELS)\n",
    "                            final_search_mask_hr = np.logical_and(search_mask_hr_corridor, search_mask_hr_user) if search_mask_hr_user is not None else search_mask_hr_corridor\n",
    "\n",
    "                            path_found_hr, came_from_hr, _ = a_star_numba_compiled(\n",
    "                                cost_data_high_res, src.nodata, start_pixel_hr, end_pixel_hr, src.res[0], abs(src.res[1]), HEURISTIC_WEIGHT, final_search_mask_hr\n",
    "                            )\n",
    "\n",
    "                        if not path_found_hr:\n",
    "                            if path_found_lr:\n",
    "                                tqdm.write(\"     ADVERTENCIA: La búsqueda en el corredor falló.\")\n",
    "                            \n",
    "                            tqdm.write(\"     PLAN B: Realizando cálculo de LCP sobre toda la máscara sin corredor...\")\n",
    "                            fallback_mask = search_mask_hr_user if search_mask_hr_user is not None else np.ones_like(cost_data_high_res, dtype=bool)\n",
    "                            path_found_hr, came_from_hr, _ = a_star_numba_compiled(\n",
    "                                cost_data_high_res, src.nodata, start_pixel_hr, end_pixel_hr, src.res[0], abs(src.res[1]), HEURISTIC_WEIGHT, fallback_mask\n",
    "                            )\n",
    "\n",
    "                        if path_found_hr:\n",
    "                            tqdm.write(f\"  -> ÉXITO: Ruta final encontrada para {ORIGIN_POINT_ID}->{dest_id}.\")\n",
    "                            path_pixels_hr = reconstruct_path_pixels_numba(came_from_hr, start_pixel_hr, end_pixel_hr)\n",
    "                            \n",
    "                            if path_found_lr:\n",
    "                                output_shp_p1 = os.path.join(OUTPUT_DIR, f\"ruta_fase1_desde_{ORIGIN_POINT_ID}_a_{dest_id}.shp\")\n",
    "                                save_path_to_shapefile(path_pixels_lr, trans_low, src.crs, output_shp_p1)\n",
    "                            \n",
    "                            output_shp_final = os.path.join(OUTPUT_DIR, f\"ruta_final_desde_{ORIGIN_POINT_ID}_a_{dest_id}.shp\")\n",
    "                            save_path_to_shapefile(path_pixels_hr, src.transform, src.crs, output_shp_final)\n",
    "                        else:\n",
    "                            tqdm.write(f\"  -> ERROR CRÍTICO: No se pudo encontrar una ruta de alto nivel para {ORIGIN_POINT_ID}->{dest_id}, ni siquiera en la búsqueda completa.\")\n",
    "\n",
    "                    print(\"\\n¡Proceso de Uno a Todos completado!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error inesperado en el proceso principal: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
