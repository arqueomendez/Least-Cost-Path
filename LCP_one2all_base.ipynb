{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a2caab9-dd63-4417-8c8d-8182fc32291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# LCP_OneToAll_Parallel_FINAL.py\n",
    "# CORRECCIÓN DEFINITIVA: Se añade una función de \"calentamiento\" (warm-up)\n",
    "# para las funciones de Numba. Esto pre-compila el código JIT en el proceso\n",
    "# principal para evitar conflictos y caídas del kernel durante la paralelización.\n",
    "# ==============================================================================\n",
    "\n",
    "# --- 1. IMPORTACIONES ---\n",
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import math\n",
    "import logging\n",
    "import time\n",
    "import threading\n",
    "import psutil\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import fiona\n",
    "from fiona.crs import CRS\n",
    "from shapely.geometry import Point, LineString, mapping, shape\n",
    "from shapely.ops import unary_union\n",
    "from numba import njit\n",
    "from skimage.draw import disk\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.features import rasterize\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35331ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recuerda que tus archivos deben llamarse 'cost.tif', 'points.shp' y 'area-mask.shp'\n",
      "La carpeta a usar será \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# --- 2. CONFIGURACIÓN DEL PROYECTO Y PARÁMETROS ---\n",
    "# ==============================================================================\n",
    "# --- 1. PARÁMETROS CONFIGURABLES POR EL USUARIO ---\n",
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "# --- 1.1 Preguntar a usuario nombre de carpeta con archivos\n",
    "\"\"\"\n",
    "Determinar carpeta con pop-up nativo del SO\n",
    "Problema -> La ventana de eleccion de carpeta aparece por debajo de la ventana actual\n",
    "data_path = askdirectory(title='Seleccionar carpeta con archivos a usar', initialdir = BASE_DIR) \n",
    "DATA_DIR = os.path.abspath(data_path)\n",
    "\"\"\"\n",
    "# Pregunta por nombre de carpeta en la línea misma\n",
    "carpeta_user = input(\"Cuál es el nombre de la carpeta con tus datos? (Tiene que estar dentro de /output): \")\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data', carpeta_user)\n",
    "print(f\"Recuerda que tus archivos deben llamarse 'cost.tif', 'points.shp' y 'area-mask.shp'\\nLa carpeta a usar será {carpeta_user}\")\n",
    "COST_RASTER_PATH = os.path.join(DATA_DIR, 'cost.tif')\n",
    "ALL_POINTS_SHAPEFILE = os.path.join(DATA_DIR, 'points.shp')\n",
    "MASK_SHAPEFILE_PATH = os.path.join(DATA_DIR, 'area-mask.shp')\n",
    "ORIGIN_POINT_ID = input(\"Desde que punto debería realizarse el análisis?: \")\n",
    "ID_FIELD_NAME = input(\"Cuál es el nombre de la columna de id en tu archivo?\")\n",
    "opcionRutas = input(\"Juntar y exportar las rutas a un solo archivo posterior al análisis? (Y/N)\")\n",
    "DOWNSAMPLING_FACTORS = [32, 20, 10]\n",
    "CORRIDOR_BUFFER_PIXELS = 150\n",
    "HEURISTIC_WEIGHT = 1.0\n",
    "N_JOBS = -2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432fe67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# --- 3. FUNCIONES (Sin cambios en su lógica interna) ---\n",
    "# ==============================================================================\n",
    "class TqdmLoggingHandler(logging.Handler):\n",
    "    def __init__(self, level=logging.NOTSET): super().__init__(level)\n",
    "    def emit(self, record):\n",
    "        try: msg = self.format(record); tqdm.write(msg); self.flush()\n",
    "        except Exception: self.handleError(record)\n",
    "\n",
    "def load_all_points(shapefile_path, id_field):\n",
    "    points = {}; crs = None\n",
    "    try:\n",
    "        with fiona.open(shapefile_path, 'r') as c:\n",
    "            crs = c.crs;\n",
    "            if len(c) == 0: logging.error(f\"'{os.path.basename(shapefile_path)}' está vacío.\"); return None, None\n",
    "            for f in c: points[int(f['properties'][id_field])] = f['geometry']['coordinates']\n",
    "        return points, crs\n",
    "    except Exception as e: logging.error(f\"Error cargando puntos: {e}\"); return None, None\n",
    "\n",
    "def load_polygon_geometry(shapefile_path):\n",
    "    if not shapefile_path or not os.path.exists(shapefile_path): return None\n",
    "    try:\n",
    "        with fiona.open(shapefile_path, 'r') as c:\n",
    "            if len(c) == 0: logging.warning(f\"'{os.path.basename(shapefile_path)}' de máscara está vacío.\"); return None\n",
    "            return unary_union([shape(f['geometry']) for f in c])\n",
    "    except Exception as e: logging.error(f\"Error cargando polígono: {e}\"); return None\n",
    "\n",
    "def world_to_pixel(transform, x, y): col, row = ~transform * (x, y); return int(row), int(col)\n",
    "def create_mask_from_vector(vector_path, raster_src):\n",
    "    if not vector_path or not os.path.exists(vector_path):\n",
    "        logging.warning(\"No se encontró archivo de máscara.\"); return None\n",
    "    with fiona.open(vector_path, \"r\") as vf:\n",
    "        if vf.crs != raster_src.crs:\n",
    "            logging.critical(f\"CRS de máscara ({vf.crs}) y ráster ({raster_src.crs}) no coinciden.\"); return None\n",
    "        shapes = [f[\"geometry\"] for f in vf]\n",
    "    return rasterize(shapes, out_shape=raster_src.shape, transform=raster_src.transform, fill=0, all_touched=True, dtype=np.uint8).astype(bool)\n",
    "\n",
    "@njit\n",
    "def heuristic_numba(r1, c1, r2, c2, dx, dy): return math.sqrt((r2 - r1)**2 + (c2 - c1)**2) * math.sqrt(dx*dy)\n",
    "@njit\n",
    "def a_star_numba_compiled(cost_array, nodata_value, start_pixel, end_pixel, dx, dy, weight, search_mask):\n",
    "    height, width = cost_array.shape; g_cost = np.full(cost_array.shape, np.inf); came_from = np.full(cost_array.shape, -1, dtype=np.int16)\n",
    "    open_set = np.zeros((1, 4)); h_initial = heuristic_numba(start_pixel[0], start_pixel[1], end_pixel[0], end_pixel[1], dx, dy)\n",
    "    open_set[0] = [h_initial*weight, 0.0, start_pixel[0], start_pixel[1]]; g_cost[start_pixel] = 0; path_found = False\n",
    "    while open_set.shape[0] > 0:\n",
    "        min_idx = np.argmin(open_set[:, 0]); f, g, r, c = open_set[min_idx]; current_pos = (int(r), int(c))\n",
    "        if open_set.shape[0] == 1: open_set = np.zeros((0, 4))\n",
    "        else: open_set = np.vstack((open_set[:min_idx], open_set[min_idx + 1:]))\n",
    "        if current_pos == end_pixel: path_found = True; break\n",
    "        if g > g_cost[current_pos]: continue\n",
    "        cost_current = cost_array[current_pos]\n",
    "        for dr in range(-1, 2):\n",
    "            for dc in range(-1, 2):\n",
    "                if dr == 0 and dc == 0: continue\n",
    "                neighbor_pos = (current_pos[0] + dr, current_pos[1] + dc)\n",
    "                if not (0 <= neighbor_pos[0] < height and 0 <= neighbor_pos[1] < width): continue\n",
    "                if not search_mask[neighbor_pos]: continue\n",
    "                cost_neighbor = cost_array[neighbor_pos];\n",
    "                if cost_neighbor == nodata_value: continue\n",
    "                dist_m = math.sqrt((dr*dy)**2 + (dc*dx)**2); avg_cost = (cost_current + cost_neighbor) / 2.0\n",
    "                tentative_g_cost = g + (avg_cost*dist_m)\n",
    "                if tentative_g_cost < g_cost[neighbor_pos]:\n",
    "                    direction = (dr+1)*3 + (dc+1); came_from[neighbor_pos] = direction; g_cost[neighbor_pos] = tentative_g_cost\n",
    "                    h = heuristic_numba(neighbor_pos[0], neighbor_pos[1], end_pixel[0], end_pixel[1], dx, dy)\n",
    "                    new_f_cost = tentative_g_cost + (h*weight)\n",
    "                    new_entry = np.array([[new_f_cost, tentative_g_cost, neighbor_pos[0], neighbor_pos[1]]])\n",
    "                    open_set = np.vstack((open_set, new_entry))\n",
    "    return path_found, came_from, g_cost\n",
    "\n",
    "@njit\n",
    "def reconstruct_path_pixels_numba(came_from_array, start_pixel, end_pixel):\n",
    "    path = np.zeros((came_from_array.size, 2), dtype=np.int32); current_pos_r, current_pos_c = end_pixel; count = 0; limit = came_from_array.size\n",
    "    while (current_pos_r, current_pos_c) != start_pixel and count < limit:\n",
    "        path[count] = np.array([current_pos_r, current_pos_c]); direction = came_from_array[current_pos_r, current_pos_c]\n",
    "        if direction == -1: return None\n",
    "        dc = (direction % 3) - 1; dr = (direction // 3) - 1; current_pos_r -= dr; current_pos_c -= dc; count += 1\n",
    "    path[count] = np.array([start_pixel[0], start_pixel[1]]); return path[:count+1][::-1]\n",
    "\n",
    "def create_low_res_data(src_transform, src_res, src_shape, cost_data_high_res, factor):\n",
    "    low_res_data = cost_data_high_res[::factor, ::factor]\n",
    "    low_res_transform = src_transform * src_transform.scale(factor, factor)\n",
    "    return low_res_data, low_res_transform, src_res[0]*factor, src_res[1]*factor\n",
    "\n",
    "def create_search_corridor(path_low_res, high_res_shape, factor, buffer_pixels):\n",
    "    corridor_mask = np.zeros(high_res_shape, dtype=bool);\n",
    "    if path_low_res is None: return corridor_mask\n",
    "    for r_low, c_low in path_low_res:\n",
    "        r_high = int(r_low*factor + factor/2); c_high = int(c_low*factor + factor/2)\n",
    "        rr, cc = disk((r_high, c_high), buffer_pixels, shape=high_res_shape); corridor_mask[rr, cc] = True\n",
    "    return corridor_mask\n",
    "def save_path_to_shapefile(pixel_path, transform, crs, output_path):\n",
    "    if pixel_path is None or not pixel_path.any():\n",
    "        print(f\"ADVERTENCIA: No se guardará {os.path.basename(output_path)}, ruta vacía.\", flush=True); return\n",
    "    world_coords = [transform * (p[1] + 0.5, p[0] + 0.5) for p in pixel_path]\n",
    "    schema = {'geometry': 'LineString', 'properties': {'id': 'str'}}\n",
    "    with fiona.open(output_path, 'w', 'ESRI Shapefile', schema, crs=CRS.from_wkt(crs.to_wkt()) if crs else None) as c:\n",
    "        c.write({'geometry': mapping(LineString(world_coords)), 'properties': {'id': os.path.basename(output_path)}})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a55dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# --- 4. NUMBA WARM-UP Y FUNCIONES DE MONITOREO ---\n",
    "# ==============================================================================\n",
    "\n",
    "def warm_up_numba():\n",
    "    \"\"\"\n",
    "    Ejecuta las funciones compiladas por Numba con datos de juguete para\n",
    "    forzar la compilación JIT en el proceso principal antes de la paralelización.\n",
    "    \"\"\"\n",
    "    log.info(\"Calentando funciones de Numba para evitar conflictos en paralelo...\")\n",
    "    # Datos de juguete\n",
    "    dummy_cost = np.ones((3, 3), dtype=np.float32)\n",
    "    dummy_mask = np.ones((3, 3), dtype=bool)\n",
    "    start = (0, 0); end = (2, 2)\n",
    "    \n",
    "    # Calentar a_star\n",
    "    _, came_from, _ = a_star_numba_compiled(dummy_cost, -9999, start, end, 1.0, 1.0, 1.0, dummy_mask)\n",
    "    \n",
    "    # Calentar reconstruct_path\n",
    "    came_from[1, 1] = 4  # Dirección de (0,0) a (1,1)\n",
    "    _ = reconstruct_path_pixels_numba(came_from, start, (1, 1))\n",
    "    \n",
    "    # Calentar heuristic\n",
    "    _ = heuristic_numba(0,0,1,1,1,1)\n",
    "    log.info(\"Calentamiento de Numba completado.\")\n",
    "\n",
    "def calculate_route_worker(args):\n",
    "    \"\"\"\n",
    "    Función de trabajo que calcula la ruta para un único destino.\n",
    "    Ahora asume que las funciones de Numba ya están compiladas.\n",
    "    \"\"\"\n",
    "    dest_id, dest_coords, shared_data = args\n",
    "    origin_id = shared_data['origin_id']\n",
    "    print(f\"--- Calculando ruta desde {origin_id} hasta {dest_id} ---\", flush=True)\n",
    "    try:\n",
    "        with rasterio.open(shared_data['cost_raster_path']) as src:\n",
    "            cost_data_high_res = src.read(1)\n",
    "            search_mask_hr_user = None\n",
    "            if shared_data['mask_shapefile_path']:\n",
    "                search_mask_hr_user = create_mask_from_vector(shared_data['mask_shapefile_path'], src)\n",
    "        start_pixel_hr = shared_data['start_pixel_hr']\n",
    "        end_pixel_hr = world_to_pixel(shared_data['transform'], dest_coords[0], dest_coords[1])\n",
    "        path_found_lr, path_pixels_lr, successful_factor, trans_low = False, None, None, None\n",
    "        print(f\"[{origin_id}->{dest_id}] -> FASE 1: Búsqueda en baja resolución...\", flush=True)\n",
    "        for factor in shared_data['downsampling_factors']:\n",
    "            cost_data_lr, trans_lr, dx_lr, dy_lr = create_low_res_data(shared_data['transform'], shared_data['res'], shared_data['shape'], cost_data_high_res, factor)\n",
    "            search_mask_lr = search_mask_hr_user[::factor, ::factor] if search_mask_hr_user is not None else np.ones(cost_data_lr.shape, dtype=bool)\n",
    "            start_lr = (start_pixel_hr[0]//factor, start_pixel_hr[1]//factor); end_lr = (end_pixel_hr[0]//factor, end_pixel_hr[1]//factor)\n",
    "            found, came_from_lr, _ = a_star_numba_compiled(cost_data_lr, shared_data['nodata'], start_lr, end_lr, dx_lr, abs(dy_lr), shared_data['heuristic_weight'], search_mask_lr)\n",
    "            if found:\n",
    "                print(f\"  [{origin_id}->{dest_id}] ÉXITO con factor {factor}.\", flush=True)\n",
    "                path_found_lr, successful_factor, trans_low = True, factor, trans_lr\n",
    "                path_pixels_lr = reconstruct_path_pixels_numba(came_from_lr, start_lr, end_lr); break\n",
    "            else:\n",
    "                print(f\"  [{origin_id}->{dest_id}] FALLÓ con factor {factor}.\", flush=True)\n",
    "        path_found_hr, came_from_hr = False, None\n",
    "        if path_found_lr:\n",
    "            corridor_mask = create_search_corridor(path_pixels_lr, shared_data['shape'], successful_factor, shared_data['corridor_buffer_pixels'])\n",
    "            final_mask = np.logical_and(corridor_mask, search_mask_hr_user) if search_mask_hr_user is not None else corridor_mask\n",
    "            path_found_hr, came_from_hr, _ = a_star_numba_compiled(cost_data_high_res, shared_data['nodata'], start_pixel_hr, end_pixel_hr, shared_data['res'][0], abs(shared_data['res'][1]), shared_data['heuristic_weight'], final_mask)\n",
    "        if not path_found_hr:\n",
    "            if path_found_lr: print(f\"  [{origin_id}->{dest_id}] Búsqueda en corredor falló.\", flush=True)\n",
    "            print(f\"  [{origin_id}->{dest_id}] PLAN B: Realizando LCP sobre toda la máscara...\", flush=True)\n",
    "            fallback_mask = search_mask_hr_user if search_mask_hr_user is not None else np.ones_like(cost_data_high_res, dtype=bool)\n",
    "            path_found_hr, came_from_hr, _ = a_star_numba_compiled(cost_data_high_res, shared_data['nodata'], start_pixel_hr, end_pixel_hr, shared_data['res'][0], abs(shared_data['res'][1]), shared_data['heuristic_weight'], fallback_mask)\n",
    "        if path_found_hr:\n",
    "            path_pixels_hr = reconstruct_path_pixels_numba(came_from_hr, start_pixel_hr, end_pixel_hr)\n",
    "            if path_found_lr:\n",
    "                p1_path = os.path.join(shared_data['session_output_dir'], f\"ruta_fase1_desde_{origin_id}_a_{dest_id}.shp\")\n",
    "                save_path_to_shapefile(path_pixels_lr, trans_low, shared_data['crs'], p1_path)\n",
    "            final_output_path = os.path.join(shared_data['session_output_dir'], f\"ruta_final_desde_{origin_id}_a_{dest_id}.shp\")\n",
    "            save_path_to_shapefile(path_pixels_hr, shared_data['transform'], shared_data['crs'], final_output_path)\n",
    "            print(f\"-> [{origin_id}->{dest_id}] ÉXITO FINAL. Ruta guardada.\", flush=True)\n",
    "            return (\"Éxito\", origin_id, dest_id)\n",
    "        else:\n",
    "            print(f\"-> [{origin_id}->{dest_id}] ERROR CRÍTICO: No se encontró ruta final.\", flush=True)\n",
    "            return (\"Fallo\", origin_id, dest_id)\n",
    "    except Exception as e:\n",
    "        print(f\"-> [{origin_id}->{dest_id}] ERROR INESPERADO: {e}\", flush=True)\n",
    "        return (\"Error\", origin_id, dest_id, str(e))\n",
    "\n",
    "def resource_monitor(stop_event, records_list, interval=1):\n",
    "    process = psutil.Process(os.getpid())\n",
    "    while not stop_event.is_set():\n",
    "        cpu = psutil.cpu_percent(interval=None)\n",
    "        mem = sum(p.memory_info().rss for p in [process] + process.children(recursive=True)) / (1024 * 1024)\n",
    "        records_list.append({'cpu': cpu, 'mem_mb': mem})\n",
    "        time.sleep(interval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82e5efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# --- 5. EJECUCIÓN DEL ANÁLISIS PARALELO ---\n",
    "# ==============================================================================\n",
    "if __name__ == '__main__':\n",
    "    os.makedirs(BASE_PROCESSING_FOLDER, exist_ok=True)\n",
    "    log_file_path = os.path.join(BASE_PROCESSING_FOLDER, \"registro_maestro_procesamiento.log\")\n",
    "    log = logging.getLogger(); log.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    if not log.handlers:\n",
    "        file_handler = logging.FileHandler(log_file_path, mode='a'); file_handler.setFormatter(formatter); log.addHandler(file_handler)\n",
    "        tqdm_handler = TqdmLoggingHandler(); tqdm_handler.setFormatter(formatter); log.addHandler(tqdm_handler)\n",
    "\n",
    "    log.info(\"=\"*50); log.info(\"INICIANDO NUEVA EJECUCIÓN PARALELA (UNO A TODOS)\"); log.info(\"=\"*50)\n",
    "    \n",
    "    # --- [INICIO DE CORRECCIÓN CRÍTICA] ---\n",
    "    # Calentar Numba ANTES de cualquier otra operación.\n",
    "    warm_up_numba()\n",
    "    # --- [FIN DE CORRECCIÓN CRÍTICA] ---\n",
    "\n",
    "    monitoring_records = []\n",
    "    try:\n",
    "        all_points, points_crs = load_all_points(ALL_POINTS_SHAPEFILE, ID_FIELD_NAME)\n",
    "        if not all_points: raise ValueError(\"No se pudieron cargar los puntos de entrada.\")\n",
    "        num_expected_routes = len(all_points) - 1\n",
    "        session_to_resume = None\n",
    "        try: existing_sessions = sorted([d for d in os.listdir(BASE_PROCESSING_FOLDER) if os.path.isdir(os.path.join(BASE_PROCESSING_FOLDER, d)) and d[:8].isdigit()])\n",
    "        except FileNotFoundError: existing_sessions = []\n",
    "        if existing_sessions:\n",
    "            latest_session_name = existing_sessions[-1]\n",
    "            latest_session_path = os.path.join(BASE_PROCESSING_FOLDER, latest_session_name)\n",
    "            completed_routes = [f for f in os.listdir(latest_session_path) if f.startswith(f\"ruta_final_desde_{ORIGIN_POINT_ID}_a_\") and f.endswith(\".shp\")]\n",
    "            if len(completed_routes) < num_expected_routes: session_to_resume = latest_session_name\n",
    "        if session_to_resume:\n",
    "            SESSION_OUTPUT_DIR = os.path.join(BASE_PROCESSING_FOLDER, session_to_resume)\n",
    "            log.info(f\"MODO REANUDACIÓN: Reanudando sesión incompleta '{session_to_resume}'.\")\n",
    "        else:\n",
    "            if existing_sessions: log.info(f\"La última sesión '{existing_sessions[-1]}' está completa.\")\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            session_folder_name = f\"{timestamp}_desde_punto_{ORIGIN_POINT_ID}\"\n",
    "            SESSION_OUTPUT_DIR = os.path.join(BASE_PROCESSING_FOLDER, session_folder_name)\n",
    "            log.info(f\"MODO NUEVO: Creando nueva sesión: {session_folder_name}\")\n",
    "        os.makedirs(SESSION_OUTPUT_DIR, exist_ok=True)\n",
    "        with rasterio.open(COST_RASTER_PATH) as src:\n",
    "            log.info(\"Validando datos y extrayendo metadatos del raster...\")\n",
    "            if MASK_SHAPEFILE_PATH:\n",
    "                mask_polygon_geom = load_polygon_geometry(MASK_SHAPEFILE_PATH)\n",
    "                if mask_polygon_geom:\n",
    "                    log.info(\"Verificando puntos contra la máscara...\")\n",
    "                    invalid_points_ids = [str(pid) for pid, coords in all_points.items() if not mask_polygon_geom.contains(Point(coords))]\n",
    "                    if invalid_points_ids:\n",
    "                        log.critical(f\"ANÁLISIS CANCELADO! Puntos fuera de máscara: {', '.join(invalid_points_ids)}\"); exit()\n",
    "                    log.info(\"VERIFICACIÓN SUPERADA.\")\n",
    "            origin_coords = all_points.get(ORIGIN_POINT_ID)\n",
    "            if origin_coords is None:\n",
    "                log.critical(f\"¡ANÁLISIS CANCELADO! El punto de origen con ID '{ORIGIN_POINT_ID}' no se encontró en '{ID_FIELD_NAME}'.\")\n",
    "                log.critical(f\"IDs disponibles: {sorted(list(all_points.keys()))}\"); exit()\n",
    "            start_pixel_hr = world_to_pixel(src.transform, origin_coords[0], origin_coords[1])\n",
    "            log.info(f\"Origen Fijo: Punto ID {ORIGIN_POINT_ID} -> Píxel {start_pixel_hr}\")\n",
    "            shared_data = {\n",
    "                'origin_id': ORIGIN_POINT_ID, 'start_pixel_hr': start_pixel_hr,\n",
    "                'cost_raster_path': COST_RASTER_PATH, 'mask_shapefile_path': MASK_SHAPEFILE_PATH,\n",
    "                'transform': src.transform, 'crs': src.crs, 'nodata': src.nodata, 'res': src.res, 'shape': src.shape,\n",
    "                'session_output_dir': SESSION_OUTPUT_DIR, 'downsampling_factors': DOWNSAMPLING_FACTORS,\n",
    "                'corridor_buffer_pixels': CORRIDOR_BUFFER_PIXELS, 'heuristic_weight': HEURISTIC_WEIGHT\n",
    "            }\n",
    "        tasks_to_run = []\n",
    "        for dest_id, dest_coords in all_points.items():\n",
    "            if dest_id == ORIGIN_POINT_ID: continue\n",
    "            final_output_path = os.path.join(SESSION_OUTPUT_DIR, f\"ruta_final_desde_{ORIGIN_POINT_ID}_a_{dest_id}.shp\")\n",
    "            if os.path.exists(final_output_path):\n",
    "                log.info(f\"Ruta para {ORIGIN_POINT_ID}->{dest_id} ya existe. Omitiendo.\")\n",
    "                continue\n",
    "            tasks_to_run.append((dest_id, dest_coords))\n",
    "        log.info(f\"Se procesarán {len(tasks_to_run)} rutas pendientes en paralelo.\")\n",
    "        if tasks_to_run:\n",
    "            full_tasks = [(dest_id, dest_coords, shared_data) for dest_id, dest_coords in tasks_to_run]\n",
    "            stop_event = threading.Event(); monitor_thread = threading.Thread(target=resource_monitor, args=(stop_event, monitoring_records))\n",
    "            start_time = time.time()\n",
    "            monitor_thread.start()\n",
    "            results = Parallel(n_jobs=N_JOBS)(\n",
    "                delayed(calculate_route_worker)(task) for task in tqdm(full_tasks, desc=\"Calculando rutas paralelas\")\n",
    "            )\n",
    "            stop_event.set(); monitor_thread.join()\n",
    "            total_duration = time.time() - start_time\n",
    "            log.info(f\"Proceso paralelo completado en {total_duration:.2f} segundos.\")\n",
    "            exitos = [r for r in results if r[0] == \"Éxito\"]\n",
    "            log.info(f\"RESUMEN: {len(exitos)} de {len(tasks_to_run)} rutas calculadas con éxito.\")\n",
    "        else:\n",
    "            log.info(\"No hay nuevas rutas que calcular en esta sesión.\")\n",
    "    except Exception as e:\n",
    "        logging.critical(f\"Error fatal en el proceso principal: {e}\", exc_info=True)\n",
    "    # Reporte exportación de rutas\n",
    "    # Loop para verificar que el usuario haya puesto la opción correcta, y en el caso de que no, dar la opción nuevamente para escribirla\n",
    "    while(True):\n",
    "        if opcionRutas in ['Y', 'y']:\n",
    "            final_route_files = glob.glob(os.path.join(OUTPUT_DIR, 'ruta_final_*.shp'))\n",
    "            if not final_route_files:\n",
    "                print(\"No se encontraron archivos de rutas finales para unir.\")\n",
    "                break\n",
    "            else:\n",
    "                final_routes_gdf = pd.concat([gpd.read_file(f) for f in final_route_files], ignore_index=True)\n",
    "                # Exportar archivo\n",
    "                # Problema -> no exporta a la carpeta específica de sesión, sino que a la carpeta output misma\n",
    "                final_routes_gdf.to_file(OUTPUT_DIR+'.shp', driver='ESRI Shapefile')\n",
    "                print(f\"Rutas unidas y exportadas a {OUTPUT_DIR}.shp\")\n",
    "                break\n",
    "        if opcionRutas in ['n', 'N']:\n",
    "            print(\"No se exportará el archivo unido.\")\n",
    "            break\n",
    "        else:\n",
    "            opcionRutas = input(\"Argumento no identificado, usar solo Y/N\")\n",
    "    finally:\n",
    "        if monitoring_records:\n",
    "            avg_cpu = np.mean([r['cpu'] for r in monitoring_records])\n",
    "            peak_mem = np.max([r['mem_mb'] for r in monitoring_records])\n",
    "            log.info(\"\\n--- Reporte de Rendimiento ---\")\n",
    "            log.info(f\"Uso promedio de CPU: {avg_cpu:.2f}%\")\n",
    "            log.info(f\"Pico de uso de Memoria: {peak_mem:.2f} MB\")\n",
    "        log.info(\"================== EJECUCIÓN FINALIZADA ==================\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c98037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# --- CELDA 6: VISUALIZACIÓN DE LA RED COMPLETA (TODOS CON TODOS) ---\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import rasterio.plot\n",
    "from rasterio.windows import from_bounds\n",
    "import glob\n",
    "\n",
    "print(\"Iniciando la visualización de la red completa de rutas...\")\n",
    "\n",
    "try:\n",
    "    # --- 1. Encontrar y cargar TODAS las rutas generadas ---\n",
    "    # MODIFICACIÓN: El patrón glob ahora busca cualquier ruta final, sin especificar origen.\n",
    "    final_route_files = glob.glob(os.path.join(OUTPUT_DIR, 'ruta_final_*.shp'))\n",
    "\n",
    "    if not final_route_files:\n",
    "        print(\"No se encontraron archivos de rutas finales para visualizar.\")\n",
    "    else:\n",
    "        # Cargar todas las rutas en un único GeoDataFrame\n",
    "        final_routes_gdf = pd.concat([gpd.read_file(f) for f in final_route_files], ignore_index=True)\n",
    "        \n",
    "        # --- 2. Determinar la extensión total con margen ---\n",
    "        minx, miny, maxx, maxy = final_routes_gdf.total_bounds\n",
    "        margin = 100\n",
    "        buffered_bounds = (minx - margin, miny - margin, maxx + margin, maxy + margin)\n",
    "        \n",
    "        # --- 3. Cargar la porción del raster ---\n",
    "        with rasterio.open(COST_RASTER_PATH) as src:\n",
    "            window = from_bounds(*buffered_bounds, transform=src.transform)\n",
    "            raster_data = src.read(1, window=window)\n",
    "            window_transform = src.window_transform(window)\n",
    "\n",
    "        # --- 4. Cargar todos los puntos ---\n",
    "        points_gdf = gpd.read_file(ALL_POINTS_SHAPEFILE)\n",
    "\n",
    "        # --- 5. Crear el mapa ---\n",
    "        fig, ax = plt.subplots(figsize=(18, 18))\n",
    "        rasterio.plot.show(raster_data, transform=window_transform, ax=ax, cmap='viridis', norm=LogNorm(), alpha=0.8)\n",
    "        \n",
    "        # MODIFICACIÓN: Dibujar todas las rutas con alta transparencia y líneas finas\n",
    "        final_routes_gdf.plot(\n",
    "            ax=ax,\n",
    "            edgecolor='red',\n",
    "            linewidth=0.8,  # Líneas más finas\n",
    "            label='Rutas Calculadas',\n",
    "            alpha=0.5,      # Alta transparencia para ver superposiciones\n",
    "            zorder=3\n",
    "        )\n",
    "        \n",
    "        # MODIFICACIÓN: Dibujar todos los puntos con el mismo estilo\n",
    "        points_gdf.plot(\n",
    "            ax=ax,\n",
    "            color='yellow',\n",
    "            markersize=50,\n",
    "            ec='black',\n",
    "            label='Nodos de la Red',\n",
    "            zorder=5\n",
    "        )\n",
    "\n",
    "        # Configuración final del mapa\n",
    "        ax.set_title('Red Completa de Rutas de Menor Costo', fontsize=20)\n",
    "        ax.set_xlabel(\"Coordenada X\"); ax.set_ylabel(\"Coordenada Y\")\n",
    "        ax.legend(); plt.grid(True, linestyle='--', alpha=0.5); plt.tight_layout(); plt.show()\n",
    "        # Configuración final del mapa\n",
    "        ax.set_title('Red Completa de Rutas de Menor Costo', fontsize=20)\n",
    "        ax.set_xlabel(\"Coordenada X\"); ax.set_ylabel(\"Coordenada Y\")\n",
    "        ax.legend(); plt.grid(True, linestyle='--', alpha=0.5); plt.tight_layout(); plt.show()\n",
    "\n",
    "        # Preguntar al usuario si quiere exportar el mapa\n",
    "        while(True):\n",
    "            opcion = str(input(\"Exportar el mapa a la carpeta /output? (Y/N)\"))\n",
    "            if opcion in ['y', 'Y']:\n",
    "                print(\"Exportando mapa...\")\n",
    "                fig.savefig(OUTPUT_DIR)\n",
    "                print(f\"{OUTPUT_DIR}.jpg exportado exitosamente a /output\")\n",
    "                break\n",
    "            if opcion in ['n', 'N']:\n",
    "                print(\"No se exportara el mapa\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"Argumento no identificado, usar solo Y/N\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error durante la visualización: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
